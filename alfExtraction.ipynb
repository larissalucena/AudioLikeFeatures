{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import numpy\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy.fftpack import fft\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import skew, kurtosis \n",
    "import spectrum \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import lfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.00000001\n",
    "n_short_blocks = 2\n",
    "c = 0.9  #threshold do spectral roll off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções criadas ou modificadas para os fluxos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareToMedian(frame, median):\n",
    "    \"\"\"Implementação do \"sign\" considerando a mediana e não a linha 0\"\"\"\n",
    "    result = numpy.empty(shape=(len(frame),))\n",
    "    for i in range(len(frame)):\n",
    "        if frame[i] > median:\n",
    "            result[i] = 1\n",
    "        elif frame[i] < median:\n",
    "            result[i] = -1\n",
    "        elif frame[i] == median:\n",
    "            result[i] = 0\n",
    "        else:\n",
    "            result[i] = math.nan\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_abs(flow, median):\n",
    "    \"\"\"Implementação do \"abs\" considerando a mediana e não a linha 0\"\"\"\n",
    "    result = numpy.empty(shape=(len(flow),))\n",
    "    \n",
    "    for i in range(len(flow)):\n",
    "        result[i] = abs(flow[i] - median) \n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-domain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stMedianCR(frame, median):\n",
    "    \"\"\"Computes median crossing rate of frame\"\"\"\n",
    "    count = len(frame)\n",
    "    countM = numpy.sum(numpy.abs(numpy.diff(compareToMedian(frame, median)))) / 2\n",
    "    return (numpy.float64(countM) / numpy.float64(count-1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stEnergy(frame):\n",
    "    \"\"\"Computes signal energy of frame\"\"\"\n",
    "    return numpy.sum(frame ** 2) / numpy.float64(len(frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flowStEnergyEntropy(frame, n_short_blocks=2):  \n",
    "    \n",
    "    \"\"\"Computes entropy of energy\"\"\"\n",
    "    L = len(frame)\n",
    "    Eol = numpy.sum(frame ** 2)    # total frame energy\n",
    "    sub_win_len = int(numpy.floor(L / n_short_blocks))  \n",
    "    if L != sub_win_len * n_short_blocks:\n",
    "            frame = frame[0:sub_win_len * n_short_blocks]  \n",
    "    # sub_wins is of size [n_short_blocks x L]\n",
    "    sub_wins = frame.reshape(sub_win_len, n_short_blocks, order='F').copy()\n",
    "\n",
    "    # Compute normalized sub-frame energies:\n",
    "    s = numpy.sum(sub_wins ** 2, axis=0) / (Eol + eps)\n",
    "\n",
    "    # Compute entropy of the normalized sub-frame energies:\n",
    "    Entropy = round(-numpy.sum(s * numpy.log2(s + eps)),10)\n",
    "    return Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stLPMCRatio(lp_frames, lp_median, frameMCRate):\n",
    "    lp_MCRate = stMedianCR(lp_frames, lp_median)\n",
    "   \n",
    "    return frameMCRate/(lp_MCRate + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amplitudedescriptors(flow):\n",
    "    abs_flow = median_abs(flow, numpy.median(flow))\n",
    "    threshold = numpy.mean(abs_flow) + numpy.std(abs_flow)\n",
    "    \n",
    "    new_LoHAS = False\n",
    "    new_LoLAS = False\n",
    "    counter_LAS = 0\n",
    "    counter_HAS = 0\n",
    "    accumulator_AHA = 0.0\n",
    "    \n",
    "    list_LoHAS = []\n",
    "    list_AHA = []\n",
    "    list_LoLAS = []\n",
    "    \n",
    "    for i in range(len(abs_flow)):\n",
    "        if (abs_flow[i] >= threshold and new_LoHAS):\n",
    "            counter_HAS = counter_HAS + 1 #continue HAS\n",
    "            accumulator_AHA = accumulator_AHA + (abs_flow[i]-threshold) #increase AHA\n",
    "        \n",
    "        elif (abs_flow[i] >= threshold and ~new_LoHAS):\n",
    "            # new HAS\n",
    "            new_LoHAS = True\n",
    "            counter_HAS = 1\n",
    "            # end LAS\n",
    "            new_LoLAS = False\n",
    "            list_LoLAS.append(counter_LAS)\n",
    "            # init AHA\n",
    "            accumulator_AHA = abs_flow[i]-threshold\n",
    "            \n",
    "        elif (abs_flow[i] < threshold and new_LoLAS):\n",
    "            #continue with LAS\n",
    "            counter_LAS = counter_LAS + 1\n",
    "\n",
    "        elif (abs_flow[i] < threshold and ~new_LoLAS):\n",
    "            if (new_LoHAS):\n",
    "                #end HAS\n",
    "                list_LoHAS.append(counter_HAS)\n",
    "                new_LoHAS = False\n",
    "                #end AHA\n",
    "                list_AHA.append(accumulator_AHA)\n",
    "            \n",
    "            #new LAS\n",
    "            new_LoLAS = True\n",
    "            counter_LAS = 1\n",
    "            \n",
    "    if  list_LoHAS == []:\n",
    "        lohas_mean = 0.0\n",
    "        lohas_std = 0.0\n",
    "        lohas_median = 0.0\n",
    "    else:\n",
    "        lohas_mean = numpy.mean(list_LoHAS)\n",
    "        lohas_std = numpy.std(list_LoHAS)\n",
    "        lohas_median = numpy.median(list_LoHAS)\n",
    "        \n",
    "    if  list_LoLAS == []:\n",
    "        lolas_mean = 0.0\n",
    "        lolas_std = 0.0\n",
    "        lolas_median = 0.0\n",
    "    else:\n",
    "        lolas_mean = numpy.mean(list_LoLAS)\n",
    "        lolas_std = numpy.std(list_LoLAS)\n",
    "        lolas_median = numpy.median(list_LoLAS)\n",
    "    \n",
    "    if  list_AHA == []:\n",
    "        aha_mean = 0.0\n",
    "    else:\n",
    "        aha_mean = numpy.mean(list_AHA)\n",
    "    \n",
    "        \n",
    "    return lohas_mean, lohas_std, lohas_median, lolas_mean, lolas_std, lolas_median, aha_mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpeg7aw(frame):\n",
    "    return numpy.amin(frame), numpy.amax(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def volume(frame):\n",
    "    return numpy.sqrt(numpy.mean(frame**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logAttackSentence(flow):\n",
    "    return math.log(numpy.argmax(flow) + eps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency-domain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stSpectralEntropy(X, n_short_blocks=n_short_blocks):\n",
    "    \"\"\"Computes the spectral entropy\"\"\"\n",
    "    L = len(X)                         # number of frame samples\n",
    "    Eol = numpy.sum(X ** 2)            # total spectral energy\n",
    "\n",
    "    sub_win_len = int(numpy.floor(L / n_short_blocks))   # length of sub-frame\n",
    "    if L != sub_win_len * n_short_blocks:\n",
    "        X = X[0:sub_win_len * n_short_blocks]\n",
    "\n",
    "    sub_wins = X.reshape(sub_win_len, n_short_blocks, order='F').copy()  # define sub-frames (using matrix reshape)\n",
    "    s = numpy.sum(sub_wins ** 2, axis=0) / (Eol + eps)                      # compute spectral sub-energies\n",
    "    En = -numpy.sum(s*numpy.log2(s + eps))                                    # compute spectral entropy\n",
    "\n",
    "    return En"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stSpectralFlux(X, X_prev):\n",
    "    \"\"\"\n",
    "    Computes the spectral flux feature of the current frame\n",
    "    ARGUMENTS:\n",
    "        X:            the abs(fft) of the current frame\n",
    "        X_prev:        the abs(fft) of the previous frame\n",
    "    \"\"\"\n",
    "    # compute the spectral flux as the sum of square distances:\n",
    "    sumX = numpy.sum(X + eps)\n",
    "    sumPrevX = numpy.sum(X_prev + eps)\n",
    "    F = numpy.sum((X / sumX - X_prev/sumPrevX) ** 2)\n",
    "\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stSpectralRollOff(X, c):#, fs):\n",
    "    \"\"\"Computes spectral roll-off\"\"\"\n",
    "    totalEnergy = numpy.sum(X ** 2)\n",
    "    fftLength = len(X)\n",
    "    Thres = c*totalEnergy\n",
    "    # Ffind the spectral rolloff as the frequency position\n",
    "    # where the respective spectral energy is equal to c*totalEnergy\n",
    "    CumSum = numpy.cumsum(X ** 2) + eps\n",
    "    [a, ] = numpy.nonzero(CumSum > Thres)\n",
    "    if len(a) > 0:\n",
    "        mC = numpy.float64(a[0]) / (float(fftLength))\n",
    "    else:\n",
    "        mC = 0.0\n",
    "    return (mC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stSpectralEnergyRatio(specframe, specflow):\n",
    "    return stEnergy(specframe)/(stEnergy(specflow) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stPitch(frame):\n",
    "    autocorrFrame, lag = spectrum.xcorr(frame, norm='biased')\n",
    "    indices = find_peaks(autocorrFrame)[0]\n",
    "    if len(indices) == 0:\n",
    "        return 0.0\n",
    "    return autocorrFrame[indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stJitter(pitches):\n",
    "    diff = []\n",
    "    for i in range(1,len(pitches)-1):\n",
    "        diff.append(pitches[i]-pitches[i-1])\n",
    "    return (abs(numpy.mean(diff)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stSpectralFlatness(frame):\n",
    "    frame_power = frame ** 2\n",
    "    gmean = numpy.exp(numpy.mean(numpy.log(frame_power + eps), axis=0, keepdims=True))\n",
    "    amean = numpy.mean(frame_power, axis=0, keepdims=True)\n",
    "    return gmean / (amean + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stSpectralCrestFactor(frame):\n",
    "    frame_power = frame ** 2\n",
    "    max = numpy.amax(frame_power)\n",
    "    amean = numpy.mean(frame_power, axis=0, keepdims=True)\n",
    "    return max / (amean + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stSpectralSkew(frame):\n",
    "    return skew(frame, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stSpectralKurtosis(frame):\n",
    "    return kurtosis(frame, bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last Frame Sentence Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertLastValueInFrames(flow, numFrames, k):\n",
    "\n",
    "    numFrames = int(numFrames)\n",
    "\n",
    "    # Signal normalization\n",
    "    flow = numpy.double(flow)\n",
    "\n",
    "    framesArray = numpy.array_split(flow, numFrames)\n",
    "    \n",
    "    min_num_sent_per_frame = k*2 # K*2 minimum number of sentences in a subframe\n",
    "    \n",
    "    padded_flow = []\n",
    "    \n",
    "    for i in range(len(framesArray)):\n",
    "        actual_frame_array = framesArray[i]\n",
    "        n = len(actual_frame_array)\n",
    "        \n",
    "        padded_frame = actual_frame_array\n",
    "        \n",
    "        if ( n < min_num_sent_per_frame): \n",
    "            if (n > 0):\n",
    "                last_value = actual_frame_array[n-1]\n",
    "            \n",
    "            for j in range(min_num_sent_per_frame - n):\n",
    "                padded_frame = numpy.append(padded_frame, last_value)\n",
    "                \n",
    "        padded_flow = numpy.append(padded_flow, padded_frame)#, axis=None)\n",
    "        \n",
    "    return padded_flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow short-term Feature Extractiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flowStFeatureExtraction(flow, flowtype, numFrames = 3):\n",
    "    \"\"\"\n",
    "    This function implements the shor-term windowing process. For each short-term window a set of features is extracted.\n",
    "    This results to a sequence of feature vectors, stored in a numpy matrix.\n",
    "\n",
    "    ARGUMENTS\n",
    "        flow:         the input flow\n",
    "        flowtype:     the flow type (arg, sen, val, mod or pre)\n",
    "        numFrames:    the number of frames the flow will be divided into\n",
    "    RETURNS\n",
    "        st_features:   a numpy array (n_feats x numOfShortTermWindows)\n",
    "        feature_names: an array containing the names os the features\n",
    "    \"\"\"\n",
    "\n",
    "    numFrames = int(numFrames)\n",
    "\n",
    "    # Signal normalization\n",
    "    flow = numpy.double(flow)\n",
    "    \n",
    "    # Median calculation - used in median crossing rate\n",
    "    median = numpy.median(flow)\n",
    "    N = len(flow)                                # total number of samples\n",
    "    \n",
    "    print(N)\n",
    "    \n",
    "    #preparing to the LP-MCR - linear prediction median-crossing ratio\n",
    "    lp_flow = numpy.insert(flow, 0, 1.0)\n",
    "    lp_flow, lp_error, lp_k= spectrum.LEVINSON(lp_flow, (len(lp_flow)-1),allow_singularity=True)\n",
    "    lp_median = numpy.median(lp_flow)\n",
    "    \n",
    "        \n",
    "    framesArray = numpy.array_split(flow, numFrames)\n",
    "    lp_framesArray = numpy.array_split(lp_flow, numFrames)\n",
    "    \n",
    "    amplitude_descriptors = amplitudedescriptors(flow)\n",
    "    \n",
    "    logAttack = logAttackSentence(flow)\n",
    "    \n",
    "    nFFT = int(len(flow)/numFrames/2) #nftt pa usar nos frames\n",
    "    \n",
    "    #FFT do sinal inteiro para cálculo da spec energy ratio\n",
    "    Y = abs(fft(flow))                     # get fft magnitude\n",
    "    Y = Y[0:int(len(flow)/2)]                          # normalize fft \n",
    "    Y = Y/len(Y)\n",
    "    \n",
    "    count_fr = 0\n",
    "    \n",
    "    n_time_feats = 8   #median crossing rate + energy + energy_entropy    \n",
    "    n_freq_feats = 9   #spectral entropy + spectral flux + spectral roll off retirei\n",
    "    n_total_feats = n_time_feats + n_freq_feats                             \n",
    "\n",
    "    feature_names = []\n",
    "\n",
    "    st_features = []\n",
    "    \n",
    "    pitches = []\n",
    "        \n",
    "    for i in range(len(framesArray)):\n",
    "        count_fr += 1\n",
    "        \n",
    "        #print(len(framesArray[i]))\n",
    "        \n",
    "        feature_names.append(\"frame_\"+str(i)+\"_\"+flowtype+\"_mcr\")\n",
    "        feature_names.append(\"frame_\"+str(i)+\"_\"+flowtype+\"_eng\")\n",
    "        feature_names.append(\"frame_\"+str(i)+\"_\"+flowtype+\"_eng_ent\")\n",
    "        feature_names.append(\"frame_\"+str(i)+\"_\"+flowtype+\"_spec_ent\")\n",
    "        feature_names.append(\"frame_\"+str(i)+\"_\"+flowtype+\"_spec_flux\")\n",
    "        feature_names.append(\"frame_\"+str(i)+\"_\"+flowtype+\"_spec_rolloff\")\n",
    "        \n",
    "        feature_names.append(\"frame_\"+str(i)+\"_\"+flowtype+\"_lp_mcr\")\n",
    "        \n",
    "        feature_names.append(\"frame_\"+str(i)+\"_\"+flowtype+\"_aw_min\")\n",
    "        feature_names.append(\"frame_\"+str(i)+\"_\"+flowtype+\"_aw_max\")\n",
    "        feature_names.append(\"frame_\"+str(i)+\"_\"+flowtype+\"_aw_diff\")\n",
    "        feature_names.append(\"frame_\"+str(i)+\"_\"+flowtype+\"_vol\")\n",
    "        \n",
    "        \n",
    "        feature_names.append(\"frame_\"+str(i)+\"_\"+flowtype+\"_spec_eng_ratio\")\n",
    "        feature_names.append(\"frame_\"+str(i)+\"_\"+flowtype+\"_pitch\")\n",
    "        feature_names.append(\"frame_\"+str(i)+\"_\"+flowtype+\"_spec_flatness\")\n",
    "        feature_names.append(\"frame_\"+str(i)+\"_\"+flowtype+\"_spec_crest_factor\")\n",
    "        feature_names.append(\"frame_\"+str(i)+\"_\"+flowtype+\"_spec_skew\")\n",
    "        feature_names.append(\"frame_\"+str(i)+\"_\"+flowtype+\"_spec_kurtosis\")\n",
    "        \n",
    "        curFV = numpy.zeros((n_total_feats, 1))\n",
    "        \n",
    "        if len(framesArray[i]) < 1:\n",
    "                     \n",
    "            curFV[0] = stMedianCR(framesArray[i], median)                 # zero crossing rate\n",
    "            curFV[1] = stEnergy(framesArray[i])                           # short-term energy\n",
    "            curFV[2] = flowStEnergyEntropy(framesArray[i])                # short-term entropy of energy        \n",
    "            curFV[3] = math.nan # stSpectralEntropy(X)\n",
    "            curFV[4] = math.nan # stSpectralFlux(X, X_prev)\n",
    "            curFV[5] = math.nan # stSpectralRollOff(X, c)\n",
    "            \n",
    "            curFV[6] = stLPMCRatio(lp_framesArray[i], lp_median, curFV[0])\n",
    "            \n",
    "            curFV[7], curFV[8] = mpeg7aw(framesArray[i])\n",
    "            curFV[9] = curFV[8] - curFV[7] #diferença entre os valores máximo e mínimo do frame - aprox de shimmer\n",
    "            \n",
    "            curFV[10] = volume(framesArray[i])\n",
    "            \n",
    "            curFV[11] = math.nan\n",
    "            curFV[12] = math.nan\n",
    "            curFv[13] = math.nan\n",
    "            curFv[14] = math.nan\n",
    "            curFv[15] = math.nan\n",
    "            curFv[16] = math.nan\n",
    "            \n",
    "            \n",
    "        else: \n",
    "           \n",
    "            X = abs(fft(framesArray[i]))                     # get fft magnitude\n",
    "            X = X[0:nFFT]                                    # normalize fft #testar sem normalizar, com o X inteiro\n",
    "            X = X/len(X)\n",
    "            \n",
    "            if count_fr == 1:\n",
    "                X_prev = X.copy()                             # keep previous fft mag (used in spectral flux)\n",
    "            \n",
    "            curFV[0] = stMedianCR(framesArray[i], median)                 # zero crossing rate\n",
    "            curFV[1] = stEnergy(framesArray[i])                           # short-term energy\n",
    "            curFV[2] = flowStEnergyEntropy(framesArray[i])                # short-term entropy of energy        \n",
    "            curFV[3] = stSpectralEntropy(X)\n",
    "            curFV[4] = stSpectralFlux(X, X_prev)\n",
    "            curFV[5] = stSpectralRollOff(X, c)\n",
    "            \n",
    "            curFV[6] = stLPMCRatio(lp_framesArray[i], lp_median, curFV[0])\n",
    "            curFV[7], curFV[8] = mpeg7aw(framesArray[i])\n",
    "            curFV[9] = curFV[8] - curFV[7] #diferença entre os valores máximo e mínimo do frame - aprox de shimmer\n",
    "            curFV[10] = volume(framesArray[i])\n",
    "            curFV[11] = stSpectralEnergyRatio(X, Y)\n",
    "            curFV[12] = stPitch(framesArray[i])\n",
    "            pitches.append(curFV[12])\n",
    "            curFV[13] = stSpectralFlatness(X)\n",
    "            curFV[14] = stSpectralCrestFactor(X)\n",
    "            curFV[15] = stSpectralSkew(X)\n",
    "            curFV[16] = stSpectralKurtosis(X)\n",
    "            \n",
    "            \n",
    "\n",
    "        st_features.append(curFV)        \n",
    "        X_prev = X.copy()\n",
    "    \n",
    "    \n",
    "    feature_names.append(flowtype+\"_ad_has_mean\")\n",
    "    feature_names.append(flowtype+\"_ad_has_std\")\n",
    "    feature_names.append(flowtype+\"_ad_has_median\")\n",
    "    feature_names.append(flowtype+\"_ad_las_mean\")\n",
    "    feature_names.append(flowtype+\"_ad_las_std\")\n",
    "    feature_names.append(flowtype+\"_ad_las_median\")\n",
    "    feature_names.append(flowtype+\"_ad_aha_mean\")\n",
    "    feature_names.append(flowtype+\"_log_attack\")\n",
    "    feature_names.append(flowtype+\"_jitter\")\n",
    "    \n",
    "    jitter = stJitter(pitches)\n",
    "    st_features = numpy.concatenate(st_features, axis=None)\n",
    "    st_features = numpy.concatenate([st_features,amplitude_descriptors], axis=None)\n",
    "    st_features = numpy.append(st_features, [logAttack,jitter])\n",
    "     \n",
    "    return st_features, feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example to extract AudioLikeFeatures using a Lexicon with two dimensions: pos and neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allFlowStFeatureExtraction(pos,neg, numFrames, k):\n",
    "\n",
    "    \"\"\"Receives all flows from a text and returns their features e features names\"\"\"\n",
    "\n",
    "    feature_names = []\n",
    "    st_features = []\n",
    "\n",
    "    cur_feature_names = []\n",
    "    cur_st_features = []\n",
    "\n",
    "    #Pos\n",
    "    cur_st_features, cur_feature_names = flowStFeatureExtraction(insertLastValueInFrames(pos, numFrames, k), 'pos', numFrames)\n",
    "    st_features.append(cur_st_features)\n",
    "    feature_names += cur_feature_names\n",
    "\n",
    "    #Neg\n",
    "    cur_st_features, cur_feature_names = flowStFeatureExtraction(insertLastValueInFrames(neg, numFrames, k), 'neg', numFrames)\n",
    "    st_features.append(cur_st_features)\n",
    "    feature_names += cur_feature_names\n",
    "\n",
    "    st_features = numpy.concatenate(st_features, axis=None)\n",
    "    return st_features, feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAllTextsAndGenerateFeaturesToCsv(input, output, numFrames, k):\n",
    "\n",
    "    \"\"\"Read the csv containing texts and flows, call allFlowStFeatureExtraction for each text and generate the resulting csv\"\"\"\n",
    "\n",
    "    data = pd.read_csv(input)\n",
    "    num_texts = data.shape[0]\n",
    "\n",
    "    pos = data['positive_flow']\n",
    "    pos = pos.apply(lambda s: [float(x.strip(' []')) for x in s.split(',')])\n",
    "    neg = data['negative_flow']\n",
    "    neg = neg.apply(lambda s: [float(x.strip(' []')) for x in s.split(',')])\n",
    "    \n",
    "    feature_names = []\n",
    "    st_features = []\n",
    "\n",
    "    cur_feature_names = []\n",
    "    cur_st_features = []\n",
    "\n",
    "    for i in range(num_texts):\n",
    "        cur_st_features, cur_feature_names = allFlowStFeatureExtraction(pos.iat[i], neg.iat[i], numFrames, k)\n",
    "        st_features.append(cur_st_features)\n",
    "\n",
    "    feature_names += cur_feature_names\n",
    "\n",
    "    texts = data['Comment']\n",
    "    labels = data['label']\n",
    "    folds = data['fold']\n",
    "    \n",
    "\n",
    "    df = pd.DataFrame(st_features, columns=feature_names)\n",
    "    df.insert(loc=0, column='label', value=labels)\n",
    "    df.insert(loc=1, column='fold', value=folds)\n",
    "    df.insert(loc=2, column='Comment', value=texts)\n",
    "\n",
    "   \n",
    "    df.to_csv(output, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
